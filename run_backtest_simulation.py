#!/usr/bin/env python3
# run_backtest_simulation.py (V2.3 - ä¿®å¤ get_dao è°ƒç”¨æ–¹å¼)

import os
import sys
import csv
import json
import time
import argparse
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

# --- 1. ç¯å¢ƒè®¾ç½® ---
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# <<< å…³é”®ä¿®æ­£ 1/2 >>>
# å¯¼å…¥æˆ‘ä»¬éœ€è¦ç”¨åˆ°çš„ DAO ç±»æœ¬èº«ï¼Œè€Œä¸æ˜¯å®ƒçš„åå­—å­—ç¬¦ä¸²
from src.database.crud.lottery_history_dao import LotteryHistoryDAO
from src.model.lottery_models import LotteryHistory
from src.database.database_manager import DatabaseManager
from src.engine.performance_logger import PerformanceLogger

# --- 2. é…ç½® (ä¿æŒä¸å˜) ---
DB_CONFIG = dict(
    host='localhost', user='root', password='123456789',
    database='lottery_analysis_system', port=3309
)
OUTPUT_DIR = os.path.join(project_root, "outputs")
DEFAULT_SLEEP_INTERVAL = 0.0

class BacktestRunner:
    # ... (è¿™ä¸ªç±»çš„å…¶ä»–éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜) ...
    def __init__(self, db_config, sleep_interval=DEFAULT_SLEEP_INTERVAL):
        self.db = DatabaseManager(**db_config)
        self.performance_logger: Optional[PerformanceLogger] = None
        self.summary_rows: List[Dict[str, Any]] = []
        self.sleep_interval = sleep_interval
        self._all_model_names = set()
    def connect(self):
        if not self.db.connect():
            raise ConnectionError("âŒ æ— æ³•è¿æ¥åˆ°æ•°æ®åº“ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        self.performance_logger = PerformanceLogger(db_manager=self.db)
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œæ‰€æœ‰ç»„ä»¶å·²åˆå§‹åŒ–ã€‚")
    def disconnect(self):
        if self.db and getattr(self.db, "_connected", False):
            self.db.disconnect()
            print("\nğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­ã€‚")
    def _get_issue_range_from_db(self) -> (Optional[int], Optional[int]):
        print("ğŸ” æ­£åœ¨è‡ªåŠ¨æ£€æµ‹å›æµ‹åŒºé—´...")
        query = """
            SELECT ar.period_number FROM algorithm_recommendation ar
            INNER JOIN lottery_history lh ON ar.period_number = lh.period_number
            WHERE ar.analysis_basis IS NOT NULL AND ar.analysis_basis != '' AND ar.analysis_basis != 'null'
            GROUP BY ar.period_number
        """
        results = self.db.execute_query(query)
        if not results: return None, None
        issues = sorted([int(r['period_number']) for r in results])
        start, end = issues[0], issues[-1]
        print(f"â¡ï¸  è‡ªåŠ¨æ£€æµ‹åˆ°æœ‰æ•ˆåŒºé—´: {start} â†’ {end}")
        return start, end
    def _get_model_outputs_for_issue(self, issue: str) -> Dict[str, Any]:
        query = "SELECT analysis_basis FROM algorithm_recommendation WHERE period_number = %s LIMIT 1"
        result = self.db.execute_query(query, (issue,))
        model_outputs = {}
        if not result or not result[0].get('analysis_basis'): return model_outputs
        try:
            raw_data_str = result[0]['analysis_basis']
            if not raw_data_str or raw_data_str.lower() == 'null': return model_outputs
            raw_data = json.loads(raw_data_str)
            if 'dynamic_ensemble_optimizer' in raw_data:
                 algorithms_data = raw_data['dynamic_ensemble_optimizer'].get('model_outputs', {})
            else:
                 algorithms_data = raw_data
            for model_name, prediction_data in algorithms_data.items():
                front = prediction_data.get('front_area', {}).get('numbers', [])
                back = prediction_data.get('back_area', {}).get('numbers', [])
                confidence = prediction_data.get('confidence', 0.5)
                if not front or not back: continue
                model_outputs[model_name] = {"front_numbers": front, "back_numbers": back, "confidence": confidence}
                self._all_model_names.add(model_name)
        except (json.JSONDecodeError, TypeError) as e:
            print(f"  - ğŸ”´ é”™è¯¯: è§£ææœŸå· {issue} çš„ analysis_basis å­—æ®µå¤±è´¥: {e}")
        return model_outputs

    def run(self, start_issue: int, end_issue: int):
        """æ‰§è¡Œå›æµ‹å’Œå­¦ä¹ çš„ä¸»å¾ªç¯ã€‚"""
        print(f"\nâ–¶ï¸  å¼€å§‹å›æµ‹ä¸å­¦ä¹ , åŒºé—´: {start_issue} â†’ {end_issue}, å…± {end_issue - start_issue + 1} æœŸ")

        # <<< å…³é”®ä¿®æ­£ 2/2 >>>
        # è°ƒç”¨ get_dao æ—¶ï¼Œä¼ é€’ LotteryHistoryDAO è¿™ä¸ªç±»ï¼Œè€Œä¸æ˜¯ 'LotteryHistoryDAO' å­—ç¬¦ä¸²
        history_dao = self.db.get_dao(LotteryHistoryDAO)

        for issue in range(start_issue, end_issue + 1):
            issue_str = str(issue)
            try:
                print("\n" + "-" * 70)
                print(f"ğŸ” å¤„ç†æœŸå·: {issue_str} ({issue - start_issue + 1}/{end_issue - start_issue + 1})")
                actual_draw = history_dao.get_by_period(issue_str)
                if not actual_draw:
                    print(f"  - â¸ï¸  è·³è¿‡: æœªæ‰¾åˆ°æœŸå· {issue_str} çš„å¼€å¥–å†å²ã€‚")
                    continue
                model_outputs = self._get_model_outputs_for_issue(issue_str)
                if not model_outputs:
                    print(f"  - â¸ï¸  è·³è¿‡: æœªæ‰¾åˆ°æœŸå· {issue_str} çš„åŸå§‹ç®—æ³•é¢„æµ‹ (analysis_basis å­—æ®µä¸ºç©ºæˆ–è§£æå¤±è´¥)ã€‚")
                    continue
                print(f"  - ğŸ§  æ‰¾åˆ° {len(model_outputs)} ä¸ªç®—æ³•é¢„æµ‹ï¼Œæ­£åœ¨è°ƒç”¨ PerformanceLogger è¿›è¡Œè¯„ä¼°å’Œå­¦ä¹ ...")
                eval_report = self.performance_logger.evaluate_and_update(
                    issue=issue_str,
                    model_outputs=model_outputs,
                    actual_draw=actual_draw
                )
                print(f"  - âœ… PerformanceLogger å¤„ç†å®Œæ¯•ã€‚è¿”å›çš„å‘½ä¸­ç‡æŠ¥å‘Š: {eval_report}")
                if eval_report:
                    row = {'issue': issue_str, 'num_models': len(model_outputs)}
                    scores = list(eval_report.values())
                    best_model = max(eval_report, key=eval_report.get) if eval_report else "N/A"
                    row.update({
                        'avg_hit_rate': sum(scores) / len(scores) if scores else 0.0,
                        'best_model_by_hit_rate': best_model,
                        'best_hit_rate': eval_report.get(best_model, 0.0),
                        **{f"hit_rate_{model}": rate for model, rate in eval_report.items()}
                    })
                    self.summary_rows.append(row)
                if self.sleep_interval > 0:
                    time.sleep(self.sleep_interval)
            except KeyboardInterrupt:
                print("\nâ›” ç”¨æˆ·ä¸­æ–­ã€‚æ­£åœ¨åœæ­¢å¹¶å¯¼å‡ºå·²æœ‰ç»“æœ...")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†æœŸå· {issue_str} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
                traceback.print_exc()
        self._export_summary_csv()
        print("\nâœ… å›æµ‹å­¦ä¹ ä»»åŠ¡å®Œæˆã€‚`algorithm_performance` è¡¨å·²ç”± PerformanceLogger æ›´æ–°ï¼")

    def _export_summary_csv(self):
        if not self.summary_rows:
            print("ï¼ˆæ— å›æµ‹æ‘˜è¦å¯å¯¼å‡ºï¼‰")
            return
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        filename = f"backtest_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = os.path.join(OUTPUT_DIR, filename)
        fieldnames = ['issue', 'num_models', 'avg_hit_rate', 'best_model_by_hit_rate', 'best_hit_rate']
        score_fields = sorted([f"hit_rate_{name}" for name in self._all_model_names])
        fieldnames.extend(score_fields)
        with open(filepath, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames, restval='N/A')
            writer.writeheader()
            writer.writerows(self.summary_rows)
        print(f"ğŸ“ å›æµ‹æ‘˜è¦å·²æˆåŠŸå¯¼å‡ºåˆ°: {filepath}")

# --- main å‡½æ•°éƒ¨åˆ†ä¿æŒä¸å˜ ---
def parse_args():
    p = argparse.ArgumentParser(description="å›æµ‹ä¸å­¦ä¹ å¼•æ“ï¼šé©±åŠ¨ PerformanceLogger è¯„ä¼°å†å²é¢„æµ‹ï¼Œæ›´æ–°æ•°æ®åº“ä¸­çš„æ€§èƒ½ä¸æƒé‡ã€‚")
    p.add_argument("--start", type=int, help="å¼€å§‹æœŸå·")
    p.add_argument("--end", type=int, help="ç»“æŸæœŸå·")
    p.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“ä¸­æ‰€æœ‰å¯è¯„ä¼°çš„æœŸå·èŒƒå›´ã€‚")
    return p.parse_args()
def main():
    args = parse_args()
    runner = BacktestRunner(DB_CONFIG)
    try:
        runner.connect()
        start, end = (None, None)
        if args.auto:
            start, end = runner._get_issue_range_from_db()
        else:
            start, end = args.start, args.end
        if not start or not end:
            print("âŒ é”™è¯¯: æ— æ³•ç¡®å®šå›æµ‹åŒºé—´ã€‚è¯·ç¡®ä¿ `algorithm_recommendation` è¡¨ä¸­æœ‰å¸¦ `analysis_basis` çš„è®°å½•ï¼Œä¸” `lottery_history` ä¸­æœ‰å¯¹åº”å¼€å¥–æ•°æ®ã€‚")
            return
        runner.run(start_issue=start, end_issue=end)
    except Exception as e:
        print(f"\nâŒ ä»»åŠ¡å¤±è´¥: {e}")
        traceback.print_exc()
    finally:
        runner.disconnect()

if __name__ == "__main__":
    main()