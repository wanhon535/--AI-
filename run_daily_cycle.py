# æ–‡ä»¶: run_daily_cycle.py (å·²ä¿®å¤ç¼©è¿›é”™è¯¯)

import os
import sys
import json
import argparse
from typing import Set

# --- ç¯å¢ƒè®¾ç½® ---
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path: sys.path.insert(0, project_root)

# --- æ ¸å¿ƒç»„ä»¶å¯¼å…¥ ---
from src.database.database_manager import DatabaseManager
from src.config.database_config import DB_CONFIG
from src.algorithms import AVAILABLE_ALGORITHMS
from src.model.lottery_models import LotteryHistory
from src.algorithms.dynamic_ensemble_optimizer import DynamicEnsembleOptimizer
from src.engine.recommendation_engine import RecommendationEngine
from src.engine.imperial_senate import ImperialSenate
from src.prompt_templates import build_final_mandate_prompt
from src.llm.clients import get_llm_client

# --- å…¨å±€é…ç½® ---
MODELS_TO_SIMULATE = ["qwen3-max",
                      "gpt-4o",  # å°†æ¥è¦ç”¨æ—¶å–æ¶ˆæ³¨é‡Š
                      "gemini-2.5-flash",
                      "deepseek-chat"]
NUM_PERIODS_TO_SIMULATE = 9999


class DailyCycleRunner:
    """ â€œå¸å›½ä¸€æ—¥â€æ€»è°ƒåº¦å™¨ (ç¨³å®šç‰ˆ) """

    def __init__(self, db_config: dict, force_rerun: bool = False):
        self.db = DatabaseManager(**db_config)
        self.force_rerun = force_rerun
        if not self.db.connect(): raise ConnectionError("æ•°æ®åº“è¿æ¥å¤±è´¥")

    def run_all(self):
        print("\n" + "#" * 70 + "\n###      â˜€ï¸  â€œå¸å›½ä¸€æ—¥â€è‡ªåŠ¨åŒ–æµç¨‹å¯åŠ¨      ###\n" + "#" * 70)
        if self.force_rerun: self._cleanup_for_rerun()
        self._run_base_algorithm_evaluation()
        self._run_full_historical_simulation()
        self._run_llm_backtesting()
        print("\n" + "#" * 70 + "\n###      ğŸŒ™  â€œå¸å›½ä¸€æ—¥â€è‡ªåŠ¨åŒ–æµç¨‹å…¨éƒ¨æ‰§è¡Œå®Œæ¯•      ###\n" + "#" * 70)
        self.db.disconnect()

    def _cleanup_for_rerun(self):
        print("\nâš ï¸  --force æ¨¡å¼ï¼Œæ­£åœ¨æ¸…ç†æ‰€æœ‰æ¨¡æ‹Ÿä¸è¯„ä¼°æ•°æ®...")
        # ä¸¥æ ¼æŒ‰é¡ºåº
        self.db.execute_update("TRUNCATE TABLE backtest_results;")
        self.db.execute_update("TRUNCATE TABLE reward_penalty_records;")
        self.db.execute_update("TRUNCATE TABLE prediction_outputs;")
        self.db.execute_update("TRUNCATE TABLE recommendation_details;")
        self.db.execute_update("TRUNCATE TABLE algorithm_recommendation;")
        self.db.execute_update("TRUNCATE TABLE algorithm_performance;")
        print("  - âœ… æ¸…ç†å®Œæ¯•ã€‚")

    def _run_base_algorithm_evaluation(self):
        print("\n" + "=" * 70 + "\n=== æ­¥éª¤ 1/3: åŸºç¡€ç®—æ³•å†å²è¡¨ç°è¯„ä¼° (æ™ºèƒ½å†™å…¥) ===")
        print("=" * 70)
        all_history_raw = self.db.execute_query("SELECT * FROM lottery_history ORDER BY period_number ASC")
        all_history = self.db._convert_rows_to_history_list(all_history_raw)
        if len(all_history) < 30: return

        for algo_name, AlgoClass in AVAILABLE_ALGORITHMS.items():
            if algo_name == "DynamicEnsembleOptimizer": continue

            print(f"\nğŸƒâ€â™‚ï¸ æ­£åœ¨è¯„ä¼°é€‰æ‰‹: {algo_name}")
            algorithm = AlgoClass()
            performance_params_list = []
            for i in range(30, len(all_history)):
                training_data, actual_draw = all_history[:i], all_history[i]
                algorithm.train(training_data)
                prediction = algorithm.predict(training_data)
                rec = prediction['recommendations'][0]
                front_scores, back_scores = rec.get('front_number_scores', []), rec.get('back_number_scores', [])
                if not front_scores or not back_scores: continue
                predicted_front, predicted_back = {item['number'] for item in front_scores[:5]}, {item['number'] for
                                                                                                  item in
                                                                                                  back_scores[:2]}
                hits = len(predicted_front & set(actual_draw.front_area)) + len(
                    predicted_back & set(actual_draw.back_area))
                confidence = rec.get('confidence', 0.5)
                hit_rate = hits / 7.0
                score = hit_rate * confidence
                performance_params_list.append(
                    (actual_draw.period_number, algo_name, algorithm.version, float(hits), round(hit_rate, 4),
                     round(score, 4))
                )

            if performance_params_list:
                print(f"  - âœï¸  æ­£åœ¨ä¸º {algo_name} æ™ºèƒ½å†™å…¥/æ›´æ–° {len(performance_params_list)} æ¡å†å²æˆ˜æŠ¥...")
                query = """
                        INSERT INTO algorithm_performance (issue, algorithm, algorithm_version, hits, hit_rate, score)
                        VALUES (%s, %s, %s, %s, %s, %s) ON DUPLICATE KEY
                        UPDATE
                            algorithm_version = \
                        VALUES (algorithm_version), hits = \
                        VALUES (hits), hit_rate = \
                        VALUES (hit_rate), score = \
                        VALUES (score), updated_at = NOW();
                        """
                success = self.db.execute_batch_insert(query, performance_params_list)
                if success:
                    print(f"  - âœ… {algo_name} çš„å†å²æˆ˜æŠ¥å·²å…¨éƒ¨æ™ºèƒ½å†™å…¥ã€‚")
                else:
                    print(f"  - âŒ {algo_name} çš„å†å²æˆ˜æŠ¥å†™å…¥å¤±è´¥ã€‚")

    # <<< è¿™é‡Œæ˜¯å…³é”®ä¿®å¤ï¼šå°†ä¸‹é¢çš„å‡½æ•°å®šä¹‰å–æ¶ˆç¼©è¿›ï¼Œä½¿å…¶æˆä¸ºç±»çš„æ­£ç¡®æ–¹æ³• >>>
    def _run_full_historical_simulation(self):
        print("\n" + "=" * 70 + "\n=== æ­¥éª¤ 2/3: LLM å…¨æµç¨‹å†å²å†³ç­–æ¨¡æ‹Ÿ (åŠ¨æ€å¼•æ“ç‰ˆ) ===")
        print("=" * 70)
        all_history_in_mem_raw = self.db.execute_query("SELECT * FROM lottery_history ORDER BY period_number ASC")
        all_history_in_mem = self.db._convert_rows_to_history_list(all_history_in_mem_raw)

        for llm_model_name in MODELS_TO_SIMULATE:
            print(f"\n--- å¼€å§‹å¯¹æ¨¡å‹: [{llm_model_name}] è¿›è¡Œæ¨¡æ‹Ÿ ---")
            periods_to_simulate = all_history_in_mem[30:]

            for i, target_draw in enumerate(periods_to_simulate, 1):
                target_period = target_draw.period_number
                print(
                    f"\n--- æ¨¡æ‹Ÿè¿›åº¦ [{llm_model_name}]: {i}/{len(periods_to_simulate)} (æœŸå·: {target_period}) ---")

                try:
                    training_data = all_history_in_mem[:30 + i - 1]

                    base_scorers = [AlgoClass() for name, AlgoClass in AVAILABLE_ALGORITHMS.items() if
                                    name != "DynamicEnsembleOptimizer"]

                    # å‡è®¾ DynamicEnsembleOptimizer æ„é€ å‡½æ•°å·²æ›´æ–°ä»¥æ¥å— db_manager
                    fusion_algorithm = DynamicEnsembleOptimizer(base_algorithms=base_scorers, db_manager=self.db)

                    engine = RecommendationEngine(base_scorers=base_scorers, fusion_algorithm=fusion_algorithm)
                    print("  - [è¯Šæ–­] æ­£åœ¨è°ƒç”¨æ ¸å¿ƒæ¨èå¼•æ“ç”Ÿæˆæ‰€æœ‰æ¨¡å‹è¾“å‡º...")
                    model_outputs = engine.generate_all_recommendations(training_data)
                    print("  - [è¯Šæ–­] å¼•æ“è¿è¡Œå®Œæ¯•ã€‚")

                    senate = ImperialSenate(self.db, {}, model_outputs)
                    edict, quant_prop, ml_brief = senate.generate_all_briefings(training_data, "ä¸ŠæœŸROI-2%")

                    prompt_text, _ = build_final_mandate_prompt(
                        recent_draws=training_data,
                        model_outputs=model_outputs,
                        performance_log={},
                        next_issue_hint=target_period,
                        last_performance_report="ä¸ŠæœŸROI-2%",
                        senate_edict=edict,
                        quant_proposal=quant_prop,
                        ml_briefing=ml_brief
                    )

                    print("  - [è¯Šæ–­] æ­£åœ¨è°ƒç”¨ LLM...")
                    llm_client = get_llm_client(llm_model_name)
                    response_str = llm_client.generate(system_prompt=prompt_text,
                                                       user_prompt="Your Majesty, your final decree.",
                                                       json_mode=True)
                    response_data = json.loads(response_str.strip().replace('```json', '').replace('```', ''))
                    print("  - [è¯Šæ–­] LLM è¿”å›å¹¶è§£ææˆåŠŸã€‚")

                    recommend_time = self.db.get_current_time()
                    meta_data = {'period_number': target_period, 'recommend_time': recommend_time,
                                 'algorithm_version': f"TheFinalMandate_{llm_model_name}_V1.2_DynamicSim",
                                 'confidence_score': 0.9 if response_data.get('self_check', {}).get('e_hits_ok',
                                                                                                    False) else 0.7,
                                 'risk_level': 'ä¸­æ€§',
                                 'analysis_basis': json.dumps(model_outputs, ensure_ascii=False, default=str),
                                 # æ·»åŠ  default=str ä»¥é˜²åºåˆ—åŒ–é—®é¢˜
                                 'llm_cognitive_details': json.dumps(
                                     {'senate_edict': edict, 'quant_proposal': json.loads(quant_prop),
                                      'ml_briefing': json.loads(ml_brief),
                                      'final_memo': response_data.get('edict', {}).get('final_memo')},
                                     ensure_ascii=False), 'models': llm_model_name}

                    recommendation_id = self.db.execute_insert('algorithm_recommendation', meta_data)
                    if not recommendation_id: recommendation_id = self.db.get_last_insert_id()
                    if not recommendation_id: raise Exception("æ’å…¥å…ƒæ•°æ®åæœªèƒ½è·å– IDã€‚")

                    final_edict = response_data.get('edict', {})
                    portfolio = final_edict.get('final_imperial_portfolio', {})
                    recommendations = portfolio.get('recommendations', [])

                    if recommendations:
                        details_to_insert = [(recommendation_id, r.get('type'), r.get('role'),
                                              ','.join(map(str, r.get('front_numbers', []))),
                                              ','.join(map(str, r.get('back_numbers', []))), r.get('sharpe')) for r
                                             in recommendations]
                        self.db.execute_batch_insert(
                            "INSERT INTO recommendation_details (recommendation_metadata_id, recommend_type, strategy_logic, front_numbers, back_numbers, win_probability) VALUES (%s, %s, %s, %s, %s, %s)",
                            details_to_insert)

                    output_data = {"recommendation_id": recommendation_id, "issue": target_period,
                                   "model_name": llm_model_name,
                                   "portfolio": json.dumps(portfolio, ensure_ascii=False),
                                   "memo": final_edict.get('final_memo'),
                                   "expected_hits_range": str(portfolio.get('overall_e_hits_range', 'N/A')),
                                   "predicted_roi": portfolio.get('allocation_summary', '')[:250],
                                   "self_check_details": json.dumps(response_data.get('self_check', {}),
                                                                    ensure_ascii=False)}
                    self.db.execute_insert('prediction_outputs', output_data)
                    print(f"  - âœ… å·²ä¸ºæœŸå· {target_period} æˆåŠŸå­˜å…¥åŒè½¨åˆ¶æ•°æ®ã€‚")

                except Exception as e:
                    print(f"\n  - âŒâŒâŒ åœ¨å¤„ç†æœŸå· {target_period} æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯ï¼ âŒâŒâŒ")
                    import traceback
                    traceback.print_exc()
                    continue

    # <<< è¿™é‡Œæ˜¯å…³é”®ä¿®å¤ï¼šå°†ä¸‹é¢çš„å‡½æ•°å®šä¹‰å–æ¶ˆç¼©è¿›ï¼Œä½¿å…¶æˆä¸ºç±»çš„æ­£ç¡®æ–¹æ³• >>>
    def _run_llm_backtesting(self):
        print("\n" + "=" * 70 + "\n=== æ­¥éª¤ 3/3: LLM å†³ç­–åŠŸç»©è¯„ä¼° (å¥–ç½šåˆ†æ˜) ===")
        print("=" * 70)
        untested_predictions = self.db.execute_query(
            "SELECT po.id, po.recommendation_id, po.issue, po.model_name, po.portfolio FROM prediction_outputs po LEFT JOIN reward_penalty_records rpr ON po.recommendation_id = rpr.recommendation_id WHERE rpr.id IS NULL")
        if not untested_predictions: print("âœ… æ‰€æœ‰å†å²å†³ç­–å‡å·²è¯„ä¼°å¹¶è®°å½•å¥–ç½šã€‚"); return
        print(f"ğŸ” å‘ç° {len(untested_predictions)} æ¡å°šæœªè¿›è¡Œå¥–ç½šè¯„ä¼°çš„å†å²å†³ç­–ã€‚")
        issues_to_check = {p['issue'] for p in untested_predictions}
        placeholders = ','.join(['%s'] * len(issues_to_check))
        history_rows = self.db.execute_query(
            f"SELECT period_number, front_area_1, front_area_2, front_area_3, front_area_4, front_area_5, back_area_1, back_area_2 FROM lottery_history WHERE period_number IN ({placeholders})",
            tuple(issues_to_check))
        actual_draws = {row['period_number']: {"front": {row[f'front_area_{i + 1}'] for i in range(5)},
                                               "back": {row[f'back_area_{i + 1}'] for i in range(2)}} for row in
                        history_rows}
        for prediction in untested_predictions:
            issue = prediction['issue']
            if issue not in actual_draws: continue
            try:
                portfolio = json.loads(prediction['portfolio'])
                recommendations = portfolio.get('recommendations', [])
                actual = actual_draws[issue]
                best_front_hits, best_back_hits = 0, 0  # åˆå§‹åŒ–ä¸º0
                for rec in recommendations:
                    pred_front, pred_back = set(map(int, rec.get('front_numbers', []))), set(
                        map(int, rec.get('back_numbers', [])))
                    front_hits, back_hits = len(pred_front & actual['front']), len(pred_back & actual['back'])
                    if front_hits + back_hits > best_front_hits + best_back_hits:
                        best_front_hits, best_back_hits = front_hits, back_hits
                hit_score = (best_front_hits * 10) + (best_back_hits * 25)
                reward_info = {"hit_score": hit_score, "reward_points": hit_score * 1.5,
                               "penalty_points": 0 if hit_score > 5 else 50,
                               "net_points": (hit_score * 1.5) - (0 if hit_score > 5 else 50)}
                reward_record_data = {"period_number": issue,
                                      "algorithm_version": f"TheFinalMandate_{prediction['model_name']}_V1.1_Simulated",
                                      "recommendation_id": prediction['recommendation_id'],
                                      "front_hit_count": best_front_hits, "back_hit_count": best_back_hits,
                                      **reward_info}
                self.db.execute_insert('reward_penalty_records', reward_record_data)
                print(
                    f"  - âœ… å·²è¯„ä¼°æœŸå· {issue} (æ¨¡å‹: {prediction['model_name']})ï¼Œå‡€å¾—åˆ†: {reward_info['net_points']}ã€‚")
            except Exception as e:
                print(f"  - âŒ è¯„ä¼°æœŸå· {issue} å¤±è´¥: {e}")
                continue


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="â€œå¸å›½ä¸€æ—¥â€æ€»è°ƒåº¦å™¨ï¼šä¸€é”®å®Œæˆæ¸…ç†ã€æ¨¡æ‹Ÿä¸è¯„ä¼°ã€‚")
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°è¿è¡Œï¼Œä¼šå…ˆæ¸…ç©ºæ‰€æœ‰å†å²æ¨¡æ‹Ÿä¸è¯„ä¼°æ•°æ®ã€‚')
    args = parser.parse_args()

    runner = DailyCycleRunner(DB_CONFIG, force_rerun=args.force)
    runner.run_all()