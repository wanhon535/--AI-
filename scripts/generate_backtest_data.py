# scripts/generate_backtest_data.py (å®Œæ•´å­—æ®µç‰ˆæœ¬)
import os
import sys
import json
from datetime import datetime

# ç¯å¢ƒè®¾ç½®
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.database.database_manager import DatabaseManager
from src.algorithms.dynamic_ensemble_optimizer import DynamicEnsembleOptimizer
from src.algorithms.statistical_algorithms import (
    FrequencyAnalysisAlgorithm, HotColdNumberAlgorithm, OmissionValueAlgorithm
)
from src.algorithms.advanced_algorithms.bayesian_number_predictor import BayesianNumberPredictor
from src.algorithms.advanced_algorithms.markov_transition_model import MarkovTransitionModel
from src.algorithms.advanced_algorithms.number_graph_analyzer import NumberGraphAnalyzer
from src.model.lottery_models import LotteryHistory
from src.engine.performance_logger import PerformanceLogger

DB_CONFIG = dict(
    host='localhost', user='root', password='123456789',
    database='lottery_analysis_system', port=3309
)


def generate_backtest_data():
    """ä¸ºå†å²æœŸå·ç”Ÿæˆå®Œæ•´çš„å›æµ‹æ•°æ®"""
    db_manager = DatabaseManager(**DB_CONFIG)
    if not db_manager.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹ç”Ÿæˆå®Œæ•´å†å²å›æµ‹æ•°æ®...")
    print("=" * 60)

    try:
        # 1. è·å–æ‰€æœ‰éœ€è¦å›æµ‹çš„å†å²æœŸå·
        all_history_dicts = db_manager.get_all_lottery_history(200)
        if not all_history_dicts or len(all_history_dicts) < 50:
            print("âŒ å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå›æµ‹æ•°æ®")
            return

        # è½¬æ¢ä¸º LotteryHistory å¯¹è±¡
        all_history_data = []
        for record_dict in all_history_dicts:
            lottery_record = LotteryHistory()
            lottery_record.period_number = record_dict['period_number']
            lottery_record.draw_date = record_dict['draw_date']
            lottery_record.front_area = [
                record_dict['front_area_1'],
                record_dict['front_area_2'],
                record_dict['front_area_3'],
                record_dict['front_area_4'],
                record_dict['front_area_5']
            ]
            lottery_record.back_area = [
                record_dict['back_area_1'],
                record_dict['back_area_2']
            ]
            all_history_data.append(lottery_record)

        # 2. è·å–éœ€è¦å›æµ‹çš„æœŸå·
        periods_to_process = []
        for i in range(50, len(all_history_data)):
            period = all_history_data[i].period_number
            periods_to_process.append(period)

        if not periods_to_process:
            print("âœ… æ‰€æœ‰å†å²æœŸå·éƒ½å·²å­˜åœ¨å›æµ‹æ•°æ®")
            return

        print(f"ğŸ“Š å‘ç° {len(periods_to_process)} ä¸ªéœ€è¦ç”Ÿæˆå›æµ‹æ•°æ®çš„æœŸå·")

        # 3. åˆå§‹åŒ–ç®—æ³•åˆ—è¡¨å’Œæ€§èƒ½è®°å½•å™¨
        base_algorithms = [
            FrequencyAnalysisAlgorithm(),
            HotColdNumberAlgorithm(),
            OmissionValueAlgorithm(),
            BayesianNumberPredictor(),
            MarkovTransitionModel(),
            NumberGraphAnalyzer(),
        ]

        performance_logger = PerformanceLogger(db_manager=db_manager)

        # 4. ä¸ºæ¯ä¸ªæœŸå·ç”Ÿæˆå®Œæ•´çš„å›æµ‹æ•°æ®
        for i, period in enumerate(periods_to_process, 1):
            print(f"\n--- æ­£åœ¨å¤„ç†æœŸå·: {period} ({i}/{len(periods_to_process)}) ---")

            try:
                # è·å–è¯¥æœŸå·ä¹‹å‰çš„å†å²æ•°æ®
                current_index = next((idx for idx, record in enumerate(all_history_data)
                                      if record.period_number == period), -1)

                if current_index == -1 or current_index < 30:
                    print(f"  - â¸ï¸ è·³è¿‡: æœŸå· {period} çš„å†å²æ•°æ®ä¸è¶³")
                    continue

                training_data = all_history_data[:current_index]

                # è¿è¡Œæ‰€æœ‰ç®—æ³•ç”Ÿæˆé¢„æµ‹
                individual_predictions = {}
                algorithm_parameters = {}

                for algorithm in base_algorithms:
                    try:
                        algorithm.train(training_data)
                        prediction = algorithm.predict(training_data)
                        individual_predictions[algorithm.name] = prediction

                        # æ”¶é›†ç®—æ³•å‚æ•°
                        algorithm_parameters[algorithm.name] = {
                            'version': getattr(algorithm, 'version', '1.0'),
                            'parameters': getattr(algorithm, 'get_parameters', lambda: {})(),
                            'trained_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        }

                        # æ’å…¥ algorithm_performance è¡¨
                        performance_data = {
                            'algorithm_version': f"{algorithm.name}_{getattr(algorithm, 'version', '1.0')}",
                            'period_number': period,
                            'predictions': json.dumps(prediction, ensure_ascii=False),
                            'confidence_score': prediction.get('confidence', 0.5),
                            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        }
                        performance_logger.dao.insert_algorithm_performance(performance_data)
                        print(f"  - âœ… {algorithm.name} é¢„æµ‹å®Œæˆå¹¶å­˜å‚¨æ€§èƒ½æ•°æ®")

                    except Exception as e:
                        print(f"  - âŒ {algorithm.name} é¢„æµ‹å¤±è´¥: {e}")
                        continue

                # ç”Ÿæˆé›†æˆé¢„æµ‹å’Œæ¨¡å‹æƒé‡
                ensemble_optimizer = DynamicEnsembleOptimizer(base_algorithms)
                ensemble_optimizer.train(training_data)
                ensemble_prediction = ensemble_optimizer.predict(training_data)

                # è·å–æ¨¡å‹æƒé‡
                model_weights = ensemble_optimizer.current_weights

                # æå–å…³é”®æ¨¡å¼
                key_patterns = {
                    'hot_numbers': individual_predictions.get('HotColdNumberAlgorithm', {}).get('hot_numbers', []),
                    'high_frequency': individual_predictions.get('FrequencyAnalysisAlgorithm', {}).get(
                        'high_frequency_numbers', []),
                    'high_omission': individual_predictions.get('OmissionValueAlgorithm', {}).get(
                        'high_omission_numbers', []),
                    'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

                # æ„å»ºå®Œæ•´çš„åˆ†æåŸºç¡€æ•°æ®
                analysis_basis = {
                    'period_number': period,
                    'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'individual_predictions': individual_predictions,  # è¿™åº”è¯¥æ˜¯å­—å…¸ï¼Œä¸æ˜¯å­—ç¬¦ä¸²
                    'ensemble_prediction': ensemble_prediction,
                    'algorithms_used': [algo.name for algo in base_algorithms],
                    'history_data_count': len(training_data),
                    'training_period_range': {
                        'start': training_data[0].period_number if training_data else None,
                        'end': training_data[-1].period_number if training_data else None
                    }
                }

                # æ’å…¥åˆ° algorithm_recommendation è¡¨ï¼ˆå®Œæ•´å­—æ®µï¼‰
                root_id = db_manager.insert_algorithm_recommendation_root(
                    period_number=period,
                    recommend_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    algorithm_version="backtest_data_generator_v2.0",
                    algorithm_parameters=json.dumps(algorithm_parameters, ensure_ascii=False),
                    model_weights=json.dumps(model_weights, ensure_ascii=False),
                    confidence_score=ensemble_prediction.get('confidence', 0.7),
                    risk_level=ensemble_prediction.get('risk_level', 'medium'),
                    analysis_basis=json.dumps(analysis_basis, ensure_ascii=False),  # ç¡®ä¿æ˜¯JSONå­—ç¬¦ä¸²
                    key_patterns=json.dumps(key_patterns, ensure_ascii=False),
                    models=','.join([algo.name for algo in base_algorithms])
                )

                if root_id:
                    # æ’å…¥æ¨èè¯¦æƒ…åˆ° recommendation_details è¡¨
                    details_to_insert = []

                    # æ·»åŠ é›†æˆæ¨è
                    ensemble_details = {
                        "recommend_type": "ensemble_prediction",
                        "strategy_logic": "åŠ¨æ€é›†æˆä¼˜åŒ–ç®—æ³•ç»¼åˆæ¨è",
                        "front_numbers": ','.join(map(str, ensemble_prediction.get('front_area', []))),
                        "back_numbers": ','.join(map(str, ensemble_prediction.get('back_area', []))),
                        "win_probability": ensemble_prediction.get('confidence', 0.7)
                    }
                    details_to_insert.append(ensemble_details)

                    # æ·»åŠ å„ç®—æ³•æ¨è
                    for algo_name, prediction in individual_predictions.items():
                        algo_details = {
                            "recommend_type": f"{algo_name}_prediction",
                            "strategy_logic": f"{algo_name}ç®—æ³•ç‹¬ç«‹æ¨è",
                            "front_numbers": ','.join(map(str, prediction.get('front_area', []))),
                            "back_numbers": ','.join(map(str, prediction.get('back_area', []))),
                            "win_probability": prediction.get('confidence', 0.5)
                        }
                        details_to_insert.append(algo_details)

                    # æ‰¹é‡æ’å…¥è¯¦æƒ…
                    db_manager.insert_recommendation_details_batch(root_id, details_to_insert)

                    print(f"  - âœ… æˆåŠŸç”Ÿæˆå®Œæ•´å›æµ‹æ•°æ®ï¼Œè®°å½•ID: {root_id}")
                    print(f"  - ğŸ“Š å­˜å‚¨äº† {len(details_to_insert)} æ¡æ¨èè¯¦æƒ…")
                else:
                    print(f"  - âŒ æ’å…¥å›æµ‹æ•°æ®å¤±è´¥")

            except Exception as e:
                print(f"  - âŒ å¤„ç†æœŸå· {period} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue

        print(f"\nâœ¨ å®Œæ•´å›æµ‹æ•°æ®ç”Ÿæˆå®Œæˆï¼å…±å¤„ç† {len(periods_to_process)} ä¸ªæœŸå·")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå›æµ‹æ•°æ®è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db_manager.disconnect()


if __name__ == "__main__":
    generate_backtest_data()