# main.py (V7.1 - å®Œæ•´æ•°æ®åº“åˆå§‹åŒ–ç‰ˆæœ¬)

import json
import os
import sys
import traceback
from datetime import datetime, timedelta

# --- 1. é¡¹ç›®ç¯å¢ƒè®¾ç½® ---
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- 2. å¯¼å…¥æ‰€æœ‰æ ¸å¿ƒç»„ä»¶ ---
from src.database.database_manager import DatabaseManager
from src.engine.performance_logger import PerformanceLogger
from src.engine.recommendation_engine import RecommendationEngine
from src.llm.clients import get_llm_client
from src.prompt_templates import build_lotto_pro_prompt_v14_omega
from src.engine.system_orchestrator import SystemOrchestrator
from run_backtest_simulation import BacktestRunner
from src.utils.logger import log_system_event

# --- 3. ç®—æ³•å¯¼å…¥ ---
from src.algorithms.dynamic_ensemble_optimizer import DynamicEnsembleOptimizer
from src.algorithms.statistical_algorithms import (
    FrequencyAnalysisAlgorithm, HotColdNumberAlgorithm, OmissionValueAlgorithm
)
from src.algorithms.advanced_algorithms.bayesian_number_predictor import BayesianNumberPredictor
from src.algorithms.advanced_algorithms.markov_transition_model import MarkovTransitionModel
from src.algorithms.advanced_algorithms.number_graph_analyzer import NumberGraphAnalyzer

# --- 4. å…¨å±€é…ç½® ---
DB_CONFIG = dict(
    host='localhost', user='root', password='123456789',
    database='lottery_analysis_system', port=3309
)


def initialize_system_tables(db_manager: DatabaseManager):
    """
    åˆå§‹åŒ–ç³»ç»Ÿä¸­æ‰€æœ‰éœ€è¦åŸºç¡€æ•°æ®çš„è¡¨ (V8 - æœ€ç»ˆå¯¹é½ç‰ˆ)
    """
    print("\n" + "=" * 60)
    print("ğŸ”„ æ­¥éª¤1.5: åˆå§‹åŒ–ç³»ç»ŸåŸºç¡€æ•°æ®è¡¨...")
    print("=" * 60)

    try:
        # --- 1. algorithm_configs (ä¿æŒä¸å˜) ---
        print("  - åˆå§‹åŒ–ç®—æ³•é…ç½®è¡¨...")
        algorithm_configs = [
            {'algorithm_name': 'FrequencyAnalysisAlgorithm', 'algorithm_type': 'statistical', 'parameters': json.dumps({'window_size': 100, 'top_n': 10}), 'description': 'é¢‘ç‡åˆ†æç®—æ³•ï¼šåŸºäºå†å²æ•°æ®è®¡ç®—æ¯ä¸ªå·ç çš„å‡ºç°é¢‘ç‡', 'version': '1.0.0', 'is_active': 1, 'is_default': 1, 'min_data_required': 50, 'expected_accuracy': 0.65, 'computation_complexity': 'low'},
            {'algorithm_name': 'HotColdNumberAlgorithm', 'algorithm_type': 'statistical', 'parameters': json.dumps({'window_size': 50, 'hot_threshold': 0.7}), 'description': 'çƒ­å†·å·ç®—æ³•ï¼šåˆ†æå·ç çš„çƒ­å†·çŠ¶æ€', 'version': '1.0.0', 'is_active': 1, 'is_default': 1, 'min_data_required': 50, 'expected_accuracy': 0.62, 'computation_complexity': 'low'},
            {'algorithm_name': 'OmissionValueAlgorithm', 'algorithm_type': 'statistical', 'parameters': json.dumps({'max_omission_threshold': 20}), 'description': 'é—æ¼å€¼ç®—æ³•ï¼šåˆ†æå·ç çš„é—æ¼æƒ…å†µ', 'version': '1.0.0', 'is_active': 1, 'is_default': 1, 'min_data_required': 50, 'expected_accuracy': 0.58, 'computation_complexity': 'low'},
            {'algorithm_name': 'BayesianNumberPredictor', 'algorithm_type': 'ml', 'parameters': json.dumps({'prior_strength': 0.5, 'update_prior': True}), 'description': 'è´å¶æ–¯é¢„æµ‹å™¨ï¼šåŸºäºè´å¶æ–¯å®šç†çš„å·ç é¢„æµ‹', 'version': '1.0.0', 'is_active': 1, 'is_default': 1, 'min_data_required': 100, 'expected_accuracy': 0.68, 'computation_complexity': 'medium'},
            {'algorithm_name': 'MarkovTransitionModel', 'algorithm_type': 'ml', 'parameters': json.dumps({'order': 2, 'smoothing': 0.1}), 'description': 'é©¬å°”å¯å¤«è½¬ç§»æ¨¡å‹ï¼šåŸºäºé©¬å°”å¯å¤«é“¾çš„å·ç è½¬ç§»é¢„æµ‹', 'version': '1.0.0', 'is_active': 1, 'is_default': 1, 'min_data_required': 100, 'expected_accuracy': 0.66, 'computation_complexity': 'medium'},
            {'algorithm_name': 'NumberGraphAnalyzer', 'algorithm_type': 'ml', 'parameters': json.dumps({'graph_type': 'co-occurrence', 'community_detection': True}), 'description': 'å·ç å›¾åˆ†æå™¨ï¼šåŸºäºå›¾ç½‘ç»œçš„å·ç å…³è”åˆ†æ', 'version': '1.0.0', 'is_active': 1, 'is_default': 1, 'min_data_required': 150, 'expected_accuracy': 0.63, 'computation_complexity': 'high'}
        ]
        for config in algorithm_configs:
            db_manager.execute_insert('algorithm_configs', config)
        print("  - âœ… algorithm_configs è¡¨åˆå§‹åŒ–å®Œæˆ")

        # --- 2. æ ¸å¿ƒä¿®å¤: ä¸º algorithm_performance åˆå§‹åŒ–æ•°æ®æ·»åŠ  'issue' å’Œ 'algorithm' å­—æ®µ ---
        print("  - åˆå§‹åŒ–ç®—æ³•æ€§èƒ½è¡¨...")
        algorithm_performance_data = [
            {
                'issue': 'system_init',  # æ­£ç¡®æä¾› NOT NULL å­—æ®µ 'issue' çš„å€¼
                'algorithm': name,       # æ­£ç¡®æä¾› NOT NULL å­—æ®µ 'algorithm' çš„å€¼
                'algorithm_version': f"{name}_1.0",
                'period_number': '2024000',
                'predictions': json.dumps({'note': 'Initial placeholder'}),
                'confidence_score': 0.0,
                'hits': 0,
                'hit_rate': 0.0,
                'score': 0.0
            }
            for name in ['FrequencyAnalysisAlgorithm', 'HotColdNumberAlgorithm', 'OmissionValueAlgorithm',
                         'BayesianNumberPredictor', 'MarkovTransitionModel', 'NumberGraphAnalyzer']
        ]
        for performance in algorithm_performance_data:
            db_manager.execute_insert('algorithm_performance', performance)
        print("  - âœ… algorithm_performance è¡¨åˆå§‹åŒ–å®Œæˆ")

        # --- 3. å…¶ä»–è¡¨çš„åˆå§‹åŒ–ä¿æŒä¸å˜ (ä»£ç æŠ˜å ) ---
        print("  - åˆå§‹åŒ–A/Bæµ‹è¯•é…ç½®è¡¨...")
        ab_test_configs = [{'test_name': 'åŸºç¡€ç®—æ³•å¯¹æ¯”æµ‹è¯•', 'test_description': 'å¯¹æ¯”ç»Ÿè®¡ç®—æ³•ä¸æœºå™¨å­¦ä¹ ç®—æ³•çš„è¡¨ç°', 'algorithm_a': 'FrequencyAnalysisAlgorithm_1.0', 'algorithm_b': 'BayesianNumberPredictor_1.0', 'split_ratio': 0.5, 'test_parameters': json.dumps({'test_duration': 30, 'min_periods': 20}), 'success_metrics': json.dumps({'primary': 'hit_rate', 'secondary': 'consistency'}), 'test_status': 'draft', 'start_date': datetime.now().date().isoformat(), 'min_sample_size': 50, 'created_by': 'system'}]
        for test_config in ab_test_configs: db_manager.execute_insert('ab_test_configs', test_config)
        print("  - âœ… ab_test_configs è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–æ•°æ®æ›´æ–°æ—¥å¿—è¡¨...")
        update_log = {'update_type': 'automatic', 'data_source': 'system_initialization', 'period_range': 'system_setup', 'records_added': len(algorithm_configs) + len(algorithm_performance_data) + len(ab_test_configs), 'records_updated': 0, 'records_deleted': 0, 'update_status': 'success', 'started_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'execution_duration': 5, 'initiated_by': 'system'}
        db_manager.execute_insert('data_update_logs', update_log)
        print("  - âœ… data_update_logs è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–è´¢åŠ¡æŠ¥è¡¨...")
        financial_report = {'report_period': datetime.now().strftime('%Y-%m'), 'report_type': 'monthly', 'total_investment': 0.0, 'total_winnings': 0.0, 'net_profit': 0.0, 'return_rate': 0.0, 'total_bets': 0, 'winning_bets': 0, 'bet_success_rate': 0.0, 'algorithm_performance': json.dumps({}), 'max_drawdown': 0.0, 'generated_by': 'system'}
        db_manager.execute_insert('financial_reports', financial_report)
        print("  - âœ… financial_reports è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–æ¨¡å‹è®­ç»ƒæ—¥å¿—è¡¨...")
        training_logs = [{'algorithm_version': 'DynamicEnsembleOptimizer_1.0', 'training_date': datetime.now().date().isoformat(), 'data_start_period': '2024001', 'data_end_period': '2024100', 'training_samples': 100, 'training_parameters': json.dumps({'ensemble_method': 'weighted_average', 'update_frequency': 'weekly'}), 'feature_set': json.dumps(['frequency', 'omission', 'hot_cold', 'graph_relations']), 'training_accuracy': 0.72, 'validation_accuracy': 0.68, 'test_accuracy': 0.65, 'training_status': 'completed', 'started_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'training_duration': 120}]
        for log in training_logs: db_manager.execute_insert('model_training_logs', log)
        print("  - âœ… model_training_logs è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–ç³»ç»Ÿé€šçŸ¥è¡¨...")
        notifications = [{'user_id': 'system', 'notification_type': 'system', 'title': 'ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ', 'message': 'å½©ç¥¨åˆ†æç³»ç»Ÿå·²å®ŒæˆåŸºç¡€æ•°æ®åˆå§‹åŒ–ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ã€‚', 'related_entity_type': 'system', 'related_entity_id': 1}, {'user_id': 'admin', 'notification_type': 'system', 'title': 'æ¬¢è¿ä½¿ç”¨å½©ç¥¨åˆ†æç³»ç»Ÿ', 'message': 'ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œè¯·å¼€å§‹æ‚¨çš„åˆ†æä¹‹æ—…ã€‚', 'related_entity_type': 'system', 'related_entity_id': 1}]
        for notification in notifications: db_manager.execute_insert('notifications', notification)
        print("  - âœ… notifications è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–æ¨¡å¼è¯†åˆ«è¡¨...")
        patterns = [{'pattern_type': 'hot_number_cluster', 'pattern_description': 'çƒ­å·èšé›†æ¨¡å¼ï¼šè¿ç»­å¤šæœŸå‡ºç°çƒ­å·èšé›†ç°è±¡', 'pattern_features': json.dumps({'cluster_size': 3, 'persistence': 5}), 'pattern_signature': 'hot_cluster_v1', 'occurrence_count': 12, 'success_rate': 0.75, 'confidence_level': 0.82, 'first_occurrence_date': '2024-01-15', 'is_active': 1, 'validity_period': 30, 'related_algorithms': json.dumps(['HotColdNumberAlgorithm', 'FrequencyAnalysisAlgorithm'])}, {'pattern_type': 'omission_reversal', 'pattern_description': 'é—æ¼åè½¬æ¨¡å¼ï¼šé•¿æœŸé—æ¼å·ç çªç„¶å‡ºç°', 'pattern_features': json.dumps({'omission_threshold': 15, 'reversal_strength': 0.8}), 'pattern_signature': 'omission_reversal_v1', 'occurrence_count': 8, 'success_rate': 0.68, 'confidence_level': 0.71, 'first_occurrence_date': '2024-02-01', 'is_active': 1, 'validity_period': 45, 'related_algorithms': json.dumps(['OmissionValueAlgorithm', 'BayesianNumberPredictor'])}]
        for pattern in patterns: db_manager.execute_insert('pattern_recognition', pattern)
        print("  - âœ… pattern_recognition è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–å¥–ç½šè®°å½•è¡¨...")
        reward_records = [{'period_number': '2024100', 'algorithm_version': 'FrequencyAnalysisAlgorithm_1.0', 'recommendation_id': 1, 'front_hit_count': 3, 'back_hit_count': 1, 'hit_score': 75.0, 'reward_points': 25.0, 'penalty_points': 0.0, 'net_points': 25.0, 'hit_details': json.dumps({'front_hits': [5, 12, 23], 'back_hits': [8]}), 'missed_numbers': json.dumps({'front_missed': [7, 18], 'back_missed': [3]}), 'performance_rating': 4, 'accuracy_deviation': 0.15, 'improvement_suggestions': 'å»ºè®®ç»“åˆçƒ­å†·å·åˆ†ææé«˜å‰åŒºå‘½ä¸­ç‡'}]
        for record in reward_records: db_manager.execute_insert('reward_penalty_records', record)
        print("  - âœ… reward_penalty_records è¡¨åˆå§‹åŒ–å®Œæˆ")
        print("  - åˆå§‹åŒ–ç³»ç»Ÿç›‘æ§è¡¨...")
        monitoring_metrics = [{'metric_name': 'algorithm_accuracy', 'metric_category': 'accuracy', 'metric_value': 0.68, 'metric_unit': 'percentage', 'warning_threshold': 0.6, 'critical_threshold': 0.5, 'current_status': 'normal'}, {'metric_name': 'data_freshness', 'metric_category': 'performance', 'metric_value': 1.0, 'metric_unit': 'days', 'warning_threshold': 2.0, 'critical_threshold': 7.0, 'current_status': 'normal'}, {'metric_name': 'memory_usage', 'metric_category': 'resource', 'metric_value': 45.2, 'metric_unit': 'percentage', 'warning_threshold': 80.0, 'critical_threshold': 90.0, 'current_status': 'normal'}, {'metric_name': 'prediction_latency', 'metric_category': 'performance', 'metric_value': 2.3, 'metric_unit': 'seconds', 'warning_threshold': 5.0, 'critical_threshold': 10.0, 'current_status': 'normal'}]
        for metric in monitoring_metrics: db_manager.execute_insert('system_monitoring', metric)
        print("  - âœ… system_monitoring è¡¨åˆå§‹åŒ–å®Œæˆ")

        print("\nâœ¨ æ‰€æœ‰ç³»ç»ŸåŸºç¡€æ•°æ®è¡¨åˆå§‹åŒ–å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()


def check_system_initialization(db_manager: DatabaseManager):
    """
    æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦éœ€è¦åˆå§‹åŒ–
    """
    tables_to_check = [
        'algorithm_configs', 'algorithm_performance', 'ab_test_configs',
        'data_update_logs', 'financial_reports', 'model_training_logs',
        'notifications', 'pattern_recognition', 'reward_penalty_records',
        'system_monitoring'
    ]

    need_initialization = False

    for table in tables_to_check:
        try:
            result = db_manager.execute_query(f"SELECT COUNT(*) as count FROM {table}")
            count = result[0]['count'] if result else 0
            if count == 0:
                print(f"  - âš ï¸ {table} è¡¨ä¸ºç©ºï¼Œéœ€è¦åˆå§‹åŒ–")
                need_initialization = True
            else:
                print(f"  - âœ… {table} è¡¨å·²æœ‰æ•°æ®")
        except Exception as e:
            print(f"  - âŒ æ£€æŸ¥ {table} è¡¨æ—¶å‡ºé”™: {e}")
            need_initialization = True

    return need_initialization


def run_prediction_pipeline(db_manager: DatabaseManager):
    """
    æ‰§è¡Œå•æ¬¡é¢„æµ‹çš„ç®¡é“ (V9 - æœ€ç»ˆä¿®å¤ç‰ˆ)
    """
    print("\n" + "=" * 60)
    print("ğŸš€  æ­¥éª¤5: å¯åŠ¨ [å®Œæ•´é¢„æµ‹] ç®¡é“...")
    print("=" * 60)

    try:
        # 1. æ•°æ®è·å–
        performance_logger = PerformanceLogger(db_manager=db_manager)
        recent_draws = db_manager.get_latest_lottery_history(100)
        next_issue = db_manager.get_next_period_number()
        print(f"  - ç›®æ ‡æœŸå·: {next_issue}")

        # 2. å­¦ä¹ æœ€æ–°æƒé‡
        latest_weights = performance_logger.get_latest_adaptive_weights()
        if not latest_weights:
            print("  - âš ï¸ è­¦å‘Š: å°šæœªå­¦ä¹ åˆ°ä»»ä½•æƒé‡ï¼Œä½¿ç”¨é»˜è®¤å€¼ã€‚")
        else:
            print(f"  - âœ… å·²åŠ è½½å­¦ä¹ åˆ°çš„åŠ¨æ€æƒé‡ã€‚")

        # 3. ç®—æ³•å¼•æ“æ‰§è¡Œ
        base_algorithms = [
            FrequencyAnalysisAlgorithm(), HotColdNumberAlgorithm(), OmissionValueAlgorithm(),
            BayesianNumberPredictor(), MarkovTransitionModel(), NumberGraphAnalyzer(),
        ]

        individual_predictions = {}
        algorithm_parameters = {}

        for algorithm in base_algorithms:
            try:
                algorithm.train(recent_draws)
                prediction = algorithm.predict(recent_draws)
                individual_predictions[algorithm.name] = prediction

                algorithm_parameters[algorithm.name] = {
                    'version': getattr(algorithm, 'version', '1.0'),
                    'parameters': getattr(algorithm, 'get_parameters', lambda: {})(),
                    'trained_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

                # æ’å…¥æ¯æ¬¡çš„é¢„æµ‹æ—¥å¿—ï¼Œè¿™éƒ¨åˆ†ç°åœ¨æ˜¯æ­£ç¡®çš„
                prediction_log_entry = {
                    'period_number': next_issue,
                    'algorithm_version': f"{algorithm.name}_{getattr(algorithm, 'version', '1.0')}",
                    'predictions': json.dumps(prediction, ensure_ascii=False),
                    'confidence_score': prediction.get('confidence', 0.5)
                }
                db_manager.execute_insert('algorithm_prediction_logs', prediction_log_entry)
                print(f"  - âœ… å­˜å‚¨ {algorithm.name} é¢„æµ‹æ—¥å¿—åˆ° 'algorithm_prediction_logs' è¡¨")

            except Exception as e:
                print(f"  - âŒ ç®—æ³• {algorithm.name} æ‰§è¡Œå¤±è´¥: {e}")
                traceback.print_exc()

        # é›†æˆä¼˜åŒ–é€»è¾‘
        chief_strategy_officer = DynamicEnsembleOptimizer(base_algorithms)
        if latest_weights:
            chief_strategy_officer.current_weights = latest_weights

        engine = RecommendationEngine()
        engine.set_meta_algorithm(chief_strategy_officer)
        final_report = engine.generate_final_recommendation(
            history_data=recent_draws,
            individual_predictions=individual_predictions
        )

        model_weights = chief_strategy_officer.current_weights
        key_patterns = {
            'hot_numbers': individual_predictions.get('HotColdNumberAlgorithm', {}).get('hot_numbers', []),
            'high_frequency': individual_predictions.get('FrequencyAnalysisAlgorithm', {}).get('high_frequency_numbers',
                                                                                               []),
            'high_omission': individual_predictions.get('OmissionValueAlgorithm', {}).get('high_omission_numbers', []),
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

        # 4. LLMæœ€ç»ˆè£å†³
        prompt_text, _ = build_lotto_pro_prompt_v14_omega(
            recent_draws=recent_draws, model_outputs=final_report,
            performance_log=model_weights, next_issue_hint=next_issue,
            last_performance_report="Weights auto-learned from history."
        )
        llm_client = get_llm_client("qwen3-max")
        response_str = llm_client.generate(
            system_prompt=prompt_text,
            user_prompt="Execute your final analysis and generate the complete JSON investment portfolio."
        )

        # 5. å­˜å‚¨å®Œæ•´ç»“æœ
        response_data = json.loads(response_str)
        final_summary = response_data.get('final_summary', {})
        recommendations_from_llm = response_data['cognitive_cycle_outputs']['phase4_portfolio_construction'][
            'recommendations']

        cognitive_details = response_data.get('cognitive_cycle_outputs', {})
        # --- æ ¸å¿ƒä¿®å¤: åœ¨è°ƒç”¨å‰ï¼Œç¡®ä¿æ‰€æœ‰å­—å…¸/åˆ—è¡¨éƒ½è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸² ---
        root_id = db_manager.insert_algorithm_recommendation_root(
            period_number=next_issue,
            algorithm_version="qwen3-max (V14.5-Pr)",
            algorithm_parameters=json.dumps(algorithm_parameters, ensure_ascii=False),
            model_weights=json.dumps(model_weights, ensure_ascii=False),
            confidence_score=final_summary.get('confidence_level', 0.8),
            risk_level=final_summary.get('risk_assessment', 'medium'),
            analysis_basis=json.dumps(final_report, ensure_ascii=False),
            llm_cognitive_details=json.dumps(cognitive_details, ensure_ascii=False),
            key_patterns=json.dumps(key_patterns, ensure_ascii=False),
            models=','.join([algo.name for algo in base_algorithms])
        )

        if not root_id:
            raise Exception("æ’å…¥æ¨èä¸»è®°å½•å¤±è´¥ã€‚")

        print(f"  - âœ… æˆåŠŸä¸ºæœŸå· {next_issue} å­˜å‚¨äº†å®Œæ•´é¢„æµ‹ä¸»è®°å½• (ID: {root_id})")

        details_to_insert = [
            {"recommend_type": rec.get('type', 'Unknown'), "strategy_logic": rec.get('role_in_portfolio', ''),
             "front_numbers": ','.join(map(str, rec.get('front_numbers', []))),
             "back_numbers": ','.join(map(str, rec.get('back_numbers', []))),
             "win_probability": rec.get('confidence_score', 0.0)}
            for rec in recommendations_from_llm
        ]
        db_manager.insert_recommendation_details_batch(root_id, details_to_insert)
        print(f"  - âœ… æˆåŠŸå­˜å‚¨äº† {len(details_to_insert)} æ¡æ¨èè¯¦æƒ…åˆ° recommendation_details è¡¨")

    except Exception as e:
        print(f"\nâŒ é¢„æµ‹ç®¡é“æ‰§è¡ŒæœŸé—´å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        traceback.print_exc()

def main():
    """
    å…¨è‡ªåŠ¨æ™ºèƒ½ç®¡å®¶ä¸»ç¨‹åº - å®Œæ•´åˆå§‹åŒ–ç‰ˆæœ¬
    """
    print("\n" + "#" * 70)
    print("###       æ¬¢è¿ä½¿ç”¨ Lotto-Pro å…¨è‡ªåŠ¨æ™ºèƒ½ç®¡å®¶ V7.1       ###")
    print("#" * 70)

    db_manager = DatabaseManager(**DB_CONFIG)
    log_system_event(db_manager, user_id='system', event_type='SYSTEM_START', status='INFO', details={'version': '7.1'})
    try:
        if not db_manager.connect():
            raise ConnectionError("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢ã€‚")

        orchestrator = SystemOrchestrator(db_manager)

        # --- æ­¥éª¤1: æ£€æŸ¥ç³»ç»ŸåŸºç¡€è¡¨æ˜¯å¦éœ€è¦åˆå§‹åŒ– ---
        print("\n" + "=" * 60)
        print("ğŸ” æ­¥éª¤1: æ£€æŸ¥ç³»ç»ŸåŸºç¡€è¡¨åˆå§‹åŒ–çŠ¶æ€...")
        need_system_init = check_system_initialization(db_manager)

        if need_system_init:
            print("  - å¼€å§‹åˆå§‹åŒ–ç³»ç»ŸåŸºç¡€è¡¨...")
            initialize_system_tables(db_manager)
        else:
            print("  - âœ… æ‰€æœ‰ç³»ç»ŸåŸºç¡€è¡¨å·²åˆå§‹åŒ–ï¼Œè·³è¿‡ã€‚")

        # --- æ­¥éª¤2: æ£€æŸ¥å·ç ç»Ÿè®¡è¡¨æ˜¯å¦éœ€è¦åˆå§‹åŒ– ---
        print("\n" + "=" * 60)
        print("ğŸ” æ­¥éª¤2: æ£€æŸ¥å·ç ç»Ÿè®¡è¡¨åˆå§‹åŒ–çŠ¶æ€...")
        stats_count_result = db_manager.execute_query("SELECT COUNT(*) as count FROM number_statistics")
        stats_count = stats_count_result[0]['count'] if stats_count_result else 0
        if stats_count == 0:
            print("  - æ£€æµ‹åˆ°ç³»ç»Ÿé¦–æ¬¡è¿è¡Œï¼Œå°†æ‰§è¡Œå·ç ç»Ÿè®¡åˆå§‹åŒ–...")
            orchestrator.check_and_initialize_data()
        else:
            print("  - âœ… å·ç ç»Ÿè®¡è¡¨å·²åˆå§‹åŒ–ï¼Œè·³è¿‡ã€‚")

        # --- æ­¥éª¤3: æ£€æŸ¥å¹¶å›å¡«ç¼ºå¤±çš„å†å²åˆ†ææ•°æ® ---
        print("\n" + "=" * 60)
        print("ğŸ” æ­¥éª¤3: æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å›å¡«çš„å†å²åˆ†æ...")
        missing_basis_result = db_manager.execute_query(
            "SELECT COUNT(*) as count FROM algorithm_recommendation WHERE analysis_basis IS NULL OR analysis_basis = ''")
        missing_basis_count = missing_basis_result[0]['count'] if missing_basis_result else 0
        if missing_basis_count > 0:
            print(f"  - æ£€æµ‹åˆ° {missing_basis_count} æ¡è®°å½•ç¼ºå°‘åˆ†ææ•°æ®ï¼Œå¼€å§‹å›å¡«...")
            orchestrator.backfill_analysis_basis()
        else:
            print("  - âœ… æ‰€æœ‰å†å²è®°å½•çš„åˆ†ææ•°æ®å®Œæ•´ï¼Œè·³è¿‡ã€‚")

        # --- æ­¥éª¤4: æ£€æŸ¥å¹¶è¿è¡Œå†å²å­¦ä¹ æµç¨‹ ---
        print("\n" + "=" * 60)
        print("ğŸ” æ­¥éª¤4: æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å­¦ä¹ çš„æ–°å†å²...")
        unlearned_query = """
                    SELECT COUNT(DISTINCT period_number) as count
                    FROM algorithm_recommendation
                    WHERE (analysis_basis IS NOT NULL AND analysis_basis != '')
                    AND period_number NOT IN (SELECT DISTINCT period_number FROM algorithm_performance)
                """
        unlearned_result = db_manager.execute_query(unlearned_query)
        unlearned_count = unlearned_result[0]['count'] if unlearned_result else 0
        if unlearned_count > 0:
            print(f"  - æ£€æµ‹åˆ° {unlearned_count} æœŸå·²åˆ†æä½†æœªå­¦ä¹ çš„å†å²ï¼Œå¼€å§‹å­¦ä¹ ...")
            backtest_runner = BacktestRunner(DB_CONFIG)
            try:
                backtest_runner.connect()
                start, end = backtest_runner._get_issue_range_from_db()
                if start and end:
                    backtest_runner.run(start, end)
            finally:
                backtest_runner.disconnect()
        else:
            print("  - âœ… æ‰€æœ‰å†å²å‡å·²å­¦ä¹ ï¼Œè·³è¿‡ã€‚")

        # --- æ­¥éª¤5: æ‰§è¡Œä»Šå¤©çš„é¢„æµ‹ä»»åŠ¡ ---
        run_prediction_pipeline(db_manager)
        log_system_event(db_manager, user_id='system', event_type='SYSTEM_SHUTDOWN', status='SUCCESS')
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿä¸»æµç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc()
        log_system_event(db_manager, user_id='system', event_type='SYSTEM_FATAL_ERROR', status='FAILURE',
                         details={'error': str(e)})
    finally:
        if db_manager and getattr(db_manager, "_connected", False):
            db_manager.disconnect()
            print("\n" + "#" * 70)
            print("###                  ç³»ç»Ÿæ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•                  ###")
            print("#" * 70)


if __name__ == "__main__":
    main()