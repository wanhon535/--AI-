# test_intelligent_neural.py
import sys
import os
# ç¥ç»ç½‘ç»œé¢„æµ‹å™¨æµ‹è¯•è„šæœ¬
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.algorithms.advanced_algorithms.neural_lottery_predictor import NeuralLotteryPredictor
from src.database.database_manager import DatabaseManager
from src.config.database_config import DB_CONFIG


def test_intelligent_neural():
    """æµ‹è¯•æ™ºèƒ½æ¨ç†ç¥ç»ç½‘ç»œ"""
    print("=== æµ‹è¯•æ™ºèƒ½æ¨ç†ç¥ç»ç½‘ç»œé¢„æµ‹å™¨ ===")

    # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
    predictor = NeuralLotteryPredictor()
    print(f"ç®—æ³•åç§°: {predictor.name}")
    print(f"ç‰ˆæœ¬: {predictor.version}")

    try:
        # ä»æ•°æ®åº“è·å–çœŸå®å†å²æ•°æ®
        print("\n1. è¿æ¥æ•°æ®åº“å¹¶è·å–å†å²æ•°æ®...")
        db_manager = DatabaseManager(**DB_CONFIG)

        # è·å–å†å²æ•°æ®
        history_data = db_manager.get_all_lottery_history(limit=100)
        print(f"ä»æ•°æ®åº“è·å–åˆ° {len(history_data)} æ¡å†å²è®°å½•")

        if not history_data:
            print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰å†å²æ•°æ®ï¼Œæµ‹è¯•ç»ˆæ­¢")
            return

        # æ˜¾ç¤ºæ•°æ®èŒƒå›´
        if len(history_data) > 0:
            first_period = history_data[0].period_number
            last_period = history_data[-1].period_number
            print(f"æ•°æ®èŒƒå›´: ç¬¬{first_period}æœŸ - ç¬¬{last_period}æœŸ")

        # æµ‹è¯•è®­ç»ƒ
        print("\n2. è®­ç»ƒæ™ºèƒ½ç¥ç»ç½‘ç»œæ¨¡å‹...")
        train_success = predictor.train(history_data)
        print(f"è®­ç»ƒçŠ¶æ€: {'âœ… æˆåŠŸ' if train_success else 'âŒ å¤±è´¥'}")
        print(f"æ¨¡å‹å·²è®­ç»ƒ: {predictor.is_trained}")

        if not train_success:
            print("âŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return

        # æµ‹è¯•é¢„æµ‹
        print("\n3. è¿›è¡Œæ™ºèƒ½æ¨ç†é¢„æµ‹...")
        result = predictor.predict(history_data)

        if 'error' in result:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {result['error']}")
            return

        # æ£€æŸ¥ç»“æœç»“æ„
        print("\n4. æ£€æŸ¥é¢„æµ‹ç»“æœ:")
        print(f"ç®—æ³•åç§°: {result.get('algorithm')}")
        print(f"ç‰ˆæœ¬: {result.get('version')}")
        print(f"ç½®ä¿¡åº¦: {result.get('recommendations', [{}])[0].get('confidence', 'N/A')}")

        # æ˜¾ç¤ºæ¨ç†æ‘˜è¦
        reasoning_summary = result.get('recommendations', [{}])[0].get('reasoning_summary', '')
        print(f"æ¨ç†æ‘˜è¦: {reasoning_summary}")

        # æ˜¾ç¤ºå‰åŒºå·ç è¯„åˆ†å’Œæ¨ç†
        recommendations = result.get('recommendations', [{}])[0]
        front_scores = recommendations.get('front_number_scores', [])
        back_scores = recommendations.get('back_number_scores', [])

        print(f"\n5. å‰åŒºå·ç æ™ºèƒ½è¯„åˆ† (å‰10ä¸ª):")
        for i, score_item in enumerate(front_scores[:10]):
            reasoning = " | ".join(score_item.get('reasoning', []))
            factors = ", ".join(score_item.get('confidence_factors', []))
            print(f"  å·ç  {score_item['number']:2d}: è¯„åˆ† {score_item['score']:.4f}")
            print(f"      æ¨ç†: {reasoning}")
            print(f"      å› ç´ : {factors}")
            print()

        print(f"\n6. ååŒºå·ç æ™ºèƒ½è¯„åˆ† (å‰5ä¸ª):")
        for i, score_item in enumerate(back_scores[:5]):
            reasoning = " | ".join(score_item.get('reasoning', []))
            factors = ", ".join(score_item.get('confidence_factors', []))
            print(f"  å·ç  {score_item['number']:2d}: è¯„åˆ† {score_item['score']:.4f}")
            print(f"      æ¨ç†: {reasoning}")
            print(f"      å› ç´ : {factors}")
            print()

        # æ˜¾ç¤ºåˆ†æè¯¦æƒ…
        analysis = result.get('analysis', {})
        print(f"\n7. å¤šç»´åº¦åˆ†æè¯¦æƒ…:")

        multi_analysis = analysis.get('multi_dimensional_analysis', {})
        if 'hot_cold' in multi_analysis:
            hc = multi_analysis['hot_cold']
            print(
                f"   çƒ­å·åˆ†æ: å‰åŒº{len(hc['front']['hot'])}çƒ­/{len(hc['front']['warm'])}æ¸©/{len(hc['front']['cold'])}å†·")
            print(f"           ååŒº{len(hc['back']['hot'])}çƒ­/{len(hc['back']['warm'])}æ¸©/{len(hc['back']['cold'])}å†·")

        if 'omission' in multi_analysis:
            om = multi_analysis['omission']
            print(f"   é—æ¼åˆ†æ: å‰åŒºå¹³å‡é—æ¼{om['avg_omission']['front']:.1f}æœŸ")
            print(f"           ååŒºå¹³å‡é—æ¼{om['avg_omission']['back']:.1f}æœŸ")

        # æ˜¾ç¤ºé¢„æµ‹å¤‡æ³¨
        notes = analysis.get('prediction_notes', [])
        if notes:
            print(f"\n8. é¢„æµ‹å¤‡æ³¨:")
            for note in notes:
                print(f"   ğŸ’¡ {note}")

        # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
        feature_importance = analysis.get('feature_importance', {})
        if feature_importance:
            print(f"\n9. ç‰¹å¾é‡è¦æ€§:")
            for feature, importance in feature_importance.items():
                print(f"   {feature}: {importance:.2f}")

        print("\n=== æ™ºèƒ½æ¨ç†ç¥ç»ç½‘ç»œæµ‹è¯•å®Œæˆ ===")

        return result

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_intelligent_neural()